{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48da87f0-cc08-4306-8e56-8f6d88dda0ae",
   "metadata": {},
   "source": [
    "# Demo 2: ATEK Data Store and Model Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28e1baa-265a-4e1a-a122-c884ce4a71ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import faulthandler\n",
    "\n",
    "import logging\n",
    "import os\n",
    "# Suppress warnings from WDS lib\n",
    "os.environ[\"WDS_PYTORCH_WEIGHTS_ONLY\"] = \"1\"\n",
    "\n",
    "from logging import StreamHandler\n",
    "import numpy as np\n",
    "from typing import Dict, List, Optional\n",
    "import torch\n",
    "import sys\n",
    "import subprocess\n",
    "from itertools import islice\n",
    "from tqdm import tqdm\n",
    "\n",
    "from atek.viz.atek_visualizer import NativeAtekSampleVisualizer\n",
    "from atek.data_loaders.atek_wds_dataloader import (\n",
    "    create_native_atek_dataloader\n",
    ")\n",
    "from atek.data_loaders.cubercnn_model_adaptor import (\n",
    "    cubercnn_collation_fn,\n",
    "    create_atek_dataloader_as_cubercnn\n",
    ")\n",
    "from atek.util.file_io_utils import load_yaml_and_extract_tar_list\n",
    "\n",
    "from cubercnn.config import get_cfg_defaults\n",
    "from cubercnn.modeling.backbone import build_dla_from_vision_fpn_backbone  # noqa\n",
    "from cubercnn.modeling.meta_arch import build_model  # noqa\n",
    "from detectron2.checkpoint import DetectionCheckpointer\n",
    "from detectron2.config import get_cfg\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "faulthandler.enable()\n",
    "\n",
    "# Configure logging to display the log messages in the notebook\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.StreamHandler(sys.stdout)\n",
    "    ]\n",
    ")\n",
    "\n",
    "logger = logging.getLogger()\n",
    "\n",
    "\n",
    "# -------------------- Helper functions --------------------#\n",
    "def run_command_and_display_output(command):\n",
    "    # Start the process\n",
    "    process = subprocess.Popen(command, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "\n",
    "    # Poll process.stdout to show stdout live\n",
    "    while True:\n",
    "        output = process.stdout.readline()\n",
    "        if output == '' and process.poll() is not None:\n",
    "            break\n",
    "        if output:\n",
    "            print(output.strip())\n",
    "    rc = process.poll()\n",
    "    return rc\n",
    "\n",
    "def create_inference_model(config_file, ckpt_dir, use_cpu_only=False):\n",
    "    \"\"\"\n",
    "    Create the model for inference pipeline, with the model config.\n",
    "    \"\"\"\n",
    "    # Create default model configuration\n",
    "    model_config = get_cfg()\n",
    "    model_config.set_new_allowed(True)\n",
    "    get_cfg_defaults(model_config)\n",
    "\n",
    "    # add extra configs for data\n",
    "    model_config.MAX_TRAINING_ATTEMPTS = 3\n",
    "    model_config.TRAIN_LIST = \"\"\n",
    "    model_config.TEST_LIST = \"\"\n",
    "    model_config.TRAIN_WDS_DIR = \"\"\n",
    "    model_config.TEST_WDS_DIR = \"\"\n",
    "    model_config.ID_MAP_JSON = \"\"\n",
    "    model_config.OBJ_PROP_JSON = \"\"\n",
    "    model_config.CATEGORY_JSON = \"\"\n",
    "    model_config.DATASETS.OBJECT_DETECTION_MODE = \"\"\n",
    "    model_config.SOLVER.VAL_MAX_ITER = 0\n",
    "    model_config.SOLVER.MAX_EPOCH = 0\n",
    "\n",
    "    model_config.merge_from_file(config_file)\n",
    "    if use_cpu_only:\n",
    "        model_config.MODEL.DEVICE = \"cpu\"\n",
    "    model_config.freeze()\n",
    "\n",
    "    model = build_model(model_config, priors=None)\n",
    "\n",
    "    _ = DetectionCheckpointer(model, save_dir=ckpt_dir).resume_or_load(\n",
    "        model_config.MODEL.WEIGHTS, resume=True\n",
    "    )\n",
    "    model.eval()\n",
    "\n",
    "    return model_config, model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a756162-4135-4e3a-86c7-7f6d4479bf43",
   "metadata": {},
   "source": [
    "### Setup data and code path\n",
    "- Download trained model weights from [here](https://www.projectaria.com/async/sample/download/?bucket=atek&filename=ATEK_example_model_weights.tar). By downloading this file, you acknowledge that you have read, understood, and agree to be bound by the terms of the [CC-BY-NC 4.0 license](https://creativecommons.org/licenses/by-nc/4.0/deed.en) software license. \n",
    "- Download ATEK Data Store json file from [here](https://www.projectaria.com/datasets/adt/). \n",
    "- Note: if you are seeing contaminated warning messages about `webdataset/autodecode.py: Future Warning`, this can be resolved by installing the `beta` version of `webdataset` library: \n",
    "```\n",
    "pip uninstall webdataset\n",
    "pip install git+https://github.com/webdataset/webdataset.git@69673059ab680195f6f6d2727077f69693c60af9\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e905f8-1203-4951-8d31-06647368b5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = os.path.join(os.path.expanduser(\"~\"), \"Documents\", \"atek_data\")\n",
    "atek_src_path = os.path.join(data_dir, \"ATEK\")\n",
    "infer_viz_conf = OmegaConf.load(os.path.join(atek_src_path, \"examples\", \"data\", \"infer_viz_conf.yaml\"))\n",
    "\n",
    "# Set up trained model weight path\n",
    "model_ckpt_path = os.path.join(data_dir, \"model_weights\", \"ATEK_example_cubercnn_weights_trained_on_ADT\")\n",
    "\n",
    "# Data store json file\n",
    "atek_json_path = os.path.join(data_dir, \"AriaDigitalTwin_ATEK_download_urls.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e494ac2-7938-4ff9-b5bd-8d71b91dd735",
   "metadata": {},
   "source": [
    "## Part 1: ATEK Data Store\n",
    "**Before ATEK**: user needs to set up their own preprocessing, and run through large datasets. **time- & resource- consuming** (14 days for 10K seqs). \n",
    "\n",
    "**With ATEK**: preprocessed Aria datasets hosted on **ATEK Data Store**:  \n",
    "1. [Option 1] Download to local.\n",
    "2. [Option 2] Stream over internet.\n",
    "\n",
    "Streaming example below: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35606aa-ecc6-4a9e-80bc-a124b1092133",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, download json file from ATEK Data Store\n",
    "if not os.path.exists(atek_json_path):\n",
    "    logger.error(\"Please download AriaDigitalTwin_ATEK_download_urls.json from https://www.projectaria.com/datasets/adt/\")\n",
    "    exit()\n",
    "\n",
    "# Second, parse into streamable yaml files\n",
    "create_streamable_yaml_command = [\n",
    "    \"python3\", f\"{atek_src_path}/tools/atek_wds_data_downloader.py\",\n",
    "    \"--config-name\",\"cubercnn\",\n",
    "    \"--input-json-path\",f\"{atek_json_path}\",\n",
    "    \"--output-folder-path\",f\"{data_dir}/streamable_yamls/\",\n",
    "    \"--max-num-sequences\", \"5\",\n",
    "    \"--train-val-split-ratio\", \"0.8\"\n",
    "]\n",
    "return_code = run_command_and_display_output(create_streamable_yaml_command)\n",
    "\n",
    "logger.info(f\"Streamable yaml files created under f{data_dir}/streamable_yamls/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f0885fa-30e7-4f74-b18d-c33bd3d1814d",
   "metadata": {},
   "source": [
    "# Part 2: Run Object detection inference using pre-trained CubeRCNN model\n",
    "In this example, we demonstrate how to run model inference with preprocessed ATEK data streamed from Data Store. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a279f9e2-5f09-484f-a352-37b008dcf8de",
   "metadata": {},
   "source": [
    "### Create a PyTorch DataLoader from ATEK WDS files\n",
    "Load WDS files as ATEK format: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a780bd-2664-493d-a403-514de35aec0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create ATEK dataloader with native ATEK format.\n",
    "tar_file_urls = load_yaml_and_extract_tar_list(yaml_path = os.path.join(data_dir, \"streamable_yamls\", \"streamable_validation_tars.yaml\"))\n",
    "# tar_file_urls = load_yaml_and_extract_tar_list(yaml_path = os.path.join(data_dir, \"downloaded_local_wds_adt\", \"local_all_tars.yaml\"))\n",
    "\n",
    "atek_dataloader = create_native_atek_dataloader(urls = tar_file_urls, batch_size = None, num_workers = 1)\n",
    "first_atek_sample = next(iter(atek_dataloader))\n",
    "logger.info(f\"Loading WDS into ATEK native format, each sample contains the following keys: {first_atek_sample.keys()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95742dc9-06c8-4c5b-8cb5-f2b1bcbb0329",
   "metadata": {},
   "source": [
    "### Create PyTorch DataLoader, converted to CubeRCNN format\n",
    "User can add a data transform function from ATEK format -> CubeRCNN format: \n",
    "1. Dict key remapping.\n",
    "2. Tensor reshaping & reordering. \n",
    "3. Other data transformations.\n",
    "\n",
    "User can follow this [guide](https://github.com/facebookresearch/ATEK/blob/main/docs/ModelAdaptors.md) and these examples ([sam2](https://github.com/facebookresearch/ATEK/blob/main/docs/example_sam2_customization.md), [cubercnn](https://github.com/facebookresearch/ATEK/blob/main/docs/example_cubercnn_customization.md)) to write their own model adaptors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de7250d-461d-4411-97fc-ca64aed0e839",
   "metadata": {},
   "outputs": [],
   "source": [
    "cubercnn_dataloader = create_atek_dataloader_as_cubercnn(urls = tar_file_urls, batch_size = 6, num_workers = 1)\n",
    "first_cubercnn_sample = next(iter(cubercnn_dataloader))\n",
    "logger.info(f\"Loading WDS into CubeRCNN format, each sample contains the following keys: {first_cubercnn_sample[0].keys()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98896d1a-f1b1-4083-a628-8d1cb7293bc9",
   "metadata": {},
   "source": [
    "### Run model inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275edf96-c4a1-45c8-88e1-bd7e144bc8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# load pre-trained CubeRCNN model\n",
    "model_config_file = os.path.join(model_ckpt_path, \"config.yaml\")\n",
    "conf = OmegaConf.load(model_config_file)\n",
    "\n",
    "# setup config and model\n",
    "use_cpu_only = not torch.cuda.is_available()\n",
    "model_config, model = create_inference_model(\n",
    "    model_config_file, model_ckpt_path, use_cpu_only = use_cpu_only\n",
    ")\n",
    "\n",
    "\n",
    "# Cache inference results for visualization\n",
    "input_output_data_pairs = []\n",
    "\n",
    "# Loop over created Pytorch Dataloader, only 5 batches for demonstration\n",
    "with torch.no_grad():\n",
    "    for cubercnn_input_data in tqdm(\n",
    "       islice(cubercnn_dataloader, 5),\n",
    "        desc=\"Inference progress: \",\n",
    "    ):\n",
    "        cubercnn_model_output = model(cubercnn_input_data)\n",
    "\n",
    "        # cache inference results for visualization\n",
    "        input_output_data_pairs.append((cubercnn_input_data, cubercnn_model_output))\n",
    "\n",
    "logger.info(\"Inference completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01528549-4906-4fc1-baf9-32807cd9e4ee",
   "metadata": {},
   "source": [
    "### Visualize inference results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b6758d-69b6-49cc-afa4-33775d79a06b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from atek.viz.cubercnn_visualizer import CubercnnVisualizer\n",
    "\n",
    "# Visualize cached inference results\n",
    "logger.info(\"Visualizing inference results.\")\n",
    "cubercnn_visualizer = CubercnnVisualizer(viz_prefix = \"inference_visualizer\", conf = infer_viz_conf)\n",
    "for input_data_as_list, output_data_as_list in input_output_data_pairs:\n",
    "    for single_cubercnn_input, single_cubercnn_output in zip(input_data_as_list, output_data_as_list):\n",
    "        timestamp_ns = single_cubercnn_input[\"timestamp_ns\"]\n",
    "        # Plot RGB image\n",
    "        cubercnn_visualizer.plot_cubercnn_img(single_cubercnn_input[\"image\"], timestamp_ns = timestamp_ns)\n",
    "\n",
    "        # Plot GT and prediction in different colors\n",
    "        single_cubercnn_output[\"T_world_camera\"] = single_cubercnn_input[\"T_world_camera\"] # This patch is needed for visualization\n",
    "        cubercnn_visualizer.plot_cubercnn_dict(cubercnn_dict = single_cubercnn_input, timestamp_ns = timestamp_ns, plot_color = cubercnn_visualizer.COLOR_GREEN, suffix = \"_model_input\")\n",
    "        cubercnn_visualizer.plot_cubercnn_dict(cubercnn_dict = single_cubercnn_output, timestamp_ns = timestamp_ns, plot_color = cubercnn_visualizer.COLOR_RED, suffix = \"_model_output\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c78bc53-7eb3-4eb7-b843-0fbb29ffb3f9",
   "metadata": {},
   "source": [
    "## Part 3: Evaluate model performance\n",
    "ATEK provides **per-task**: \n",
    "1. Standardized prediction file formats.\n",
    "2. Lib for common eval metrics.\n",
    "3. Benchmarking scripts.\n",
    "\n",
    "Example prediction file format for 3D object detection: \n",
    "\n",
    "| time_ns       | tx_world_object | ty_world_object | tz_world_object | qw_world_object | qx_world_object | qy_world_object | qz_world_object | scale_x | scale_y | scale_z | name    | instance | sem_id | prob    |\n",
    "|---------------|-----------------|-----------------|-----------------|-----------------|-----------------|-----------------|-----------------|---------|---------|---------|---------|----------|--------|--------|\n",
    "| 14588033546600| -4.119894       | 0.986124        | 2.796770        | 0.008052        | -0.022706       | -0.010150       | 0.999658        | 0.190   | 2.146   | 0.900   | door    | -1       | 32     | 0.994462|\n",
    "| 14588033546600| -3.875954       | 0.837941        | 4.056602        | 0.009215        | -0.015670       | 0.999661        | -0.018645       | 0.325   | 1.697   | 0.964   | display | -1       | 37     | 0.994381|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20571759-3efa-46d3-822a-dcc068f25907",
   "metadata": {},
   "source": [
    "### Write inference results into ATEK-format csv files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610926ea-501d-4b7d-9457-6920e10150e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from atek.evaluation.static_object_detection.obb3_csv_io import AtekObb3CsvWriter\n",
    "\n",
    "gt_writer = AtekObb3CsvWriter(output_filename = os.path.join(data_dir, \"gt_obbs.csv\"))\n",
    "prediction_writer = AtekObb3CsvWriter(output_filename = os.path.join(data_dir, \"prediction_obbs.csv\"))\n",
    "\n",
    "for input_data_as_list, output_data_as_list in input_output_data_pairs:\n",
    "    for single_cubercnn_input, single_cubercnn_output in zip(input_data_as_list, output_data_as_list):\n",
    "        timestamp_ns = single_cubercnn_input[\"timestamp_ns\"]\n",
    "        single_cubercnn_output[\"T_world_camera\"] = single_cubercnn_input[\"T_world_camera\"]\n",
    "\n",
    "        gt_writer.write_from_cubercnn_dict(cubercnn_dict = single_cubercnn_input, timestamp_ns = timestamp_ns)\n",
    "        prediction_writer.write_from_cubercnn_dict(cubercnn_dict = single_cubercnn_output, timestamp_ns = timestamp_ns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5942d47a-ffad-4aa2-95a1-48d4d502686d",
   "metadata": {},
   "source": [
    "### Call ATEK's benchmarking script to evaluate the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e1370c7-b3ff-479b-82f0-75534d00e264",
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmarking_command = [\n",
    "    \"python3\", f\"{atek_src_path}/tools/benchmarking_static_object_detection.py\",\n",
    "    \"--pred-csv\", f\"{data_dir}/prediction_obbs.csv\",\n",
    "    \"--gt-csv\", f\"{data_dir}/gt_obbs.csv\",\n",
    "    \"--output-file\", f\"{data_dir}/atek_metrics.json\"\n",
    "]\n",
    "return_code = run_command_and_display_output(benchmarking_command)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4
}
