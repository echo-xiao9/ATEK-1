{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "924Eqh3ErHWn"
   },
   "source": [
    "# ATEK CoLab Notebook\n",
    "\n",
    "Welcome to ATEK CoLab Notebook. This notebook\n",
    " will walk through the steps of preparing an Aria data sequence with annotations ([AriaDigitalTwin (ADT)](https://www.projectaria.com/datasets/adt/)), for use in a 3D object detection ML task.\n",
    "We will go through the following steps:\n",
    "1. downloading ADT sample data\n",
    "2. preprocess ADT sample data\n",
    "3. visualize the preprocessed data\n",
    "4. run model inference with ATEK preprocessed data\n",
    "5. evaluate model performance.\n",
    "\n",
    "## Environment set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "YygI9xSxQJen",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "!pip install 'git+https://github.com/YLouWashU/omni3d.git'\n",
    "!pip install projectaria-atek==1.0.0\n",
    "!pip install 'git+https://github.com/facebookresearch/detectron2.git'\n",
    "!pip install iopath\n",
    "import sys\n",
    "import torch\n",
    "pyt_version_str=torch.__version__.split(\"+\")[0].replace(\".\", \"\")\n",
    "version_str=\"\".join([\n",
    "    f\"py3{sys.version_info.minor}_cu\",\n",
    "    torch.version.cuda.replace(\".\",\"\"),\n",
    "    f\"_pyt{pyt_version_str}\"\n",
    "])\n",
    "!pip install --no-index --no-cache-dir pytorch3d -f https://dl.fbaipublicfiles.com/pytorch3d/packaging/wheels/{version_str}/download.html\n",
    "!pip install rerun-sdk[notebook]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mejA1LJYoqny"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "url = \"https://www.projectaria.com/async/sample/download/?bucket=atek&filename=ATEK_example_model_weights.tar\"\n",
    "response = requests.get(url)\n",
    "\n",
    "# Specify the path where you want to save the file\n",
    "file_path = \"/content/ATEK_example_model_weights.tar\"\n",
    "\n",
    "# Open the file in binary write mode and write the contents of the response\n",
    "with open(file_path, \"wb\") as file:\n",
    "    file.write(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "s2-IjOuiBsim",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "!mkdir -p /content/data\n",
    "!tar -xvf /content/ATEK_example_model_weights.tar -C /content/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "EUZA4zzGfrdJ",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "!cd /content/data\n",
    "!git clone https://github.com/facebookresearch/ATEK.git\n",
    "!unzip /content/atek.zip -d /content/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3j8s4r7VM1y_"
   },
   "outputs": [],
   "source": [
    "print(\"----debug: manually upload zip file\")\n",
    "!unzip /content/ATEK-main.zip -d /content/data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tTp3xS-Ggpe4"
   },
   "source": [
    "## Part1: Data proprocessing\n",
    "\n",
    "###  Data preprocessing requirements\n",
    "ADT sequence has:\n",
    "1. Aria recording (VRS).\n",
    "2. MPS trajectory file (CSV).\n",
    "3. Object detection annotation files (3 csv files + 1 json file).\n",
    "\n",
    "CubeRCNN model needs synchronized data frame containing:\n",
    "1. Upright RGB camera image.\n",
    "2. Linear camera calibration matrix.\n",
    "3. Object bounding box annotations in 2D + 3D.\n",
    "4. Camera-to-object poses.\n",
    "\n",
    "**Before ATEK**, users need to implement all the followings to prepare ADT sequence into CubeRCNN model:\n",
    "1. Parse in ADT sequence data using `projectaria_tools` lib.   \n",
    "2. Properly synchronize sensor + annotation data into training samples.\n",
    "3. Perform additional image & data processing:\n",
    "    1. Undistort image + camera calibration.\n",
    "    2. Rescale camera resolution.\n",
    "    3. Rotate image + camera calibration.\n",
    "    4. Undistort + rescale + rotate object 2D bounding boxes accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "Yy79EFR8UZMS",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import faulthandler\n",
    "import logging\n",
    "import os\n",
    "from logging import StreamHandler\n",
    "import numpy as np\n",
    "from typing import Dict, List, Optional\n",
    "import torch\n",
    "import sys\n",
    "from itertools import islice\n",
    "from tqdm import tqdm\n",
    "\n",
    "from atek.data_preprocess.genera_atek_preprocessor_factory import (\n",
    "    create_general_atek_preprocessor_from_conf,\n",
    ")\n",
    "from atek.viz.atek_visualizer import NativeAtekSampleVisualizer\n",
    "from atek.data_preprocess.general_atek_preprocessor import GeneralAtekPreprocessor\n",
    "from atek.data_loaders.atek_wds_dataloader import (\n",
    "    create_native_atek_dataloader\n",
    ")\n",
    "\n",
    "from atek.data_loaders.cubercnn_model_adaptor import (\n",
    "    cubercnn_collation_fn,\n",
    "    create_atek_dataloader_as_cubercnn\n",
    ")\n",
    "from atek.evaluation.static_object_detection.obb3_csv_io import AtekObb3CsvWriter\n",
    "\n",
    "from atek.data_preprocess.atek_data_sample import (\n",
    "    create_atek_data_sample_from_flatten_dict,\n",
    ")\n",
    "from cubercnn.config import get_cfg_defaults\n",
    "from cubercnn.modeling.backbone import build_dla_from_vision_fpn_backbone\n",
    "from cubercnn.modeling.meta_arch import build_model\n",
    "\n",
    "from detectron2.checkpoint import DetectionCheckpointer\n",
    "from detectron2.config import get_cfg\n",
    "from omegaconf import OmegaConf\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YJNAP3W2g_CL"
   },
   "source": [
    "## Download ADT sequences from projectaria.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "Fy-pj5ejrMn8",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "adt_sample_path = \"./adt_sample_data\"\n",
    "data_sequence_url = \"https://www.projectaria.com/async/sample/download/?bucket=adt&filename=aria_digital_twin_test_data_v2.zip\"\n",
    "command_list = [\n",
    "    f\"mkdir -p {adt_sample_path}\",\n",
    "    # Download sample data\n",
    "    f'curl -o {adt_sample_path}/adt_sample_data.zip -C - -O -L \"{data_sequence_url}\"',\n",
    "    # Unzip the sample data\n",
    "    f\"unzip -o {adt_sample_path}/adt_sample_data.zip -d {adt_sample_path}\"\n",
    "]\n",
    "sequence_path = f\"{adt_sample_path}/Apartment_release_golden_skeleton_seq100_10s_sample_M1292\"\n",
    "\n",
    "# Execute the commands for downloading dataset\n",
    "for command in command_list:\n",
    "    subprocess.run(command, shell=True, check=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mGJc-2B_hF03"
   },
   "source": [
    "###  Set up data and code paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KGaKsE5IEol8"
   },
   "outputs": [],
   "source": [
    "example_adt_data_dir = f\"{adt_sample_path}/Apartment_release_golden_skeleton_seq100_10s_sample_M1292\"\n",
    "sequence_name = \"Apartment_release_golden_skeleton_seq100_10s_sample_M1292\"\n",
    "atek_src_path = \"/content/data/ATEK-main\"\n",
    "category_mapping_file = f\"{atek_src_path}/data/adt_prototype_to_atek.csv\"\n",
    "atek_preprocess_config_path = f\"{atek_src_path}/examples/data/adt_cubercnn_preprocess_config.yaml\"\n",
    "preprocess_conf = OmegaConf.load(atek_preprocess_config_path)\n",
    "# Take viz conf out of preprocess conf\n",
    "viz_conf = preprocess_conf.visualizer\n",
    "del preprocess_conf.visualizer\n",
    "\n",
    "# Create viz conf for inference viewer\n",
    "infer_viz_config_path = f\"{atek_src_path}/examples/data/infer_viz_conf.yaml\"\n",
    "infer_viz_conf = OmegaConf.load(infer_viz_config_path)\n",
    "\n",
    "output_wds_path = f\"{atek_src_path}/examples/data/wds_output\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nBcS5GTahgx5"
   },
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uw-Yzp1pjyJd"
   },
   "outputs": [],
   "source": [
    "faulthandler.enable()\n",
    "\n",
    "# Configure logging to display the log messages in the notebook\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.StreamHandler(sys.stdout)\n",
    "    ]\n",
    ")\n",
    "\n",
    "logger = logging.getLogger()\n",
    "\n",
    "\n",
    "# -------------------- Helper functions --------------------#\n",
    "def print_data_sample_dict_content(data_sample, if_pretty: bool = False):\n",
    "    \"\"\"\n",
    "    A helper function to print the content of data sample dict\n",
    "    \"\"\"\n",
    "    logger.info(\"Printing the content in a ATEK data sample dict: \")\n",
    "    for key, val in data_sample.items():\n",
    "        if if_pretty and \"#\" in key:\n",
    "            key = key.split(\"#\", 1)[1]\n",
    "\n",
    "        msg = f\"\\t {key}: is a {type(val)}, \"\n",
    "        if isinstance(val, torch.Tensor):\n",
    "            msg += f\"\\n \\t\\t\\t\\t with tensor dtype of {val.dtype}, and shape of : {val.shape}\"\n",
    "        elif isinstance(val, list):\n",
    "            msg += f\"with len of : {len(val)}\"\n",
    "        elif isinstance(val, str):\n",
    "            msg += f\"value is {val}\"\n",
    "        else:\n",
    "            pass\n",
    "        logger.info(msg)\n",
    "\n",
    "def run_command_and_display_output(command):\n",
    "    # Start the process\n",
    "    process = subprocess.Popen(command, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "\n",
    "    # Poll process.stdout to show stdout live\n",
    "    while True:\n",
    "        output = process.stdout.readline()\n",
    "        if output == '' and process.poll() is not None:\n",
    "            break\n",
    "        if output:\n",
    "            print(output.strip())\n",
    "    rc = process.poll()\n",
    "    return rc\n",
    "\n",
    "def create_inference_model(config_file, ckpt_dir, use_cpu_only=False):\n",
    "    \"\"\"\n",
    "    Create the model for inference pipeline, with the model config.\n",
    "    \"\"\"\n",
    "    # Create default model configuration\n",
    "    model_config = get_cfg()\n",
    "    model_config.set_new_allowed(True)\n",
    "    get_cfg_defaults(model_config)\n",
    "\n",
    "    # add extra configs for data\n",
    "    model_config.MAX_TRAINING_ATTEMPTS = 3\n",
    "    model_config.TRAIN_LIST = \"\"\n",
    "    model_config.TEST_LIST = \"\"\n",
    "    model_config.TRAIN_WDS_DIR = \"\"\n",
    "    model_config.TEST_WDS_DIR = \"\"\n",
    "    model_config.ID_MAP_JSON = \"\"\n",
    "    model_config.OBJ_PROP_JSON = \"\"\n",
    "    model_config.CATEGORY_JSON = \"\"\n",
    "    model_config.DATASETS.OBJECT_DETECTION_MODE = \"\"\n",
    "    model_config.SOLVER.VAL_MAX_ITER = 0\n",
    "    model_config.SOLVER.MAX_EPOCH = 0\n",
    "\n",
    "    model_config.merge_from_file(config_file)\n",
    "    if use_cpu_only:\n",
    "        model_config.MODEL.DEVICE = \"cpu\"\n",
    "    model_config.freeze()\n",
    "\n",
    "    model = build_model(model_config, priors=None)\n",
    "\n",
    "    _ = DetectionCheckpointer(model, save_dir=ckpt_dir).resume_or_load(\n",
    "        model_config.MODEL.WEIGHTS, resume=True\n",
    "    )\n",
    "    model.eval()\n",
    "\n",
    "    return model_config, model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rvdmyAIrhngs"
   },
   "source": [
    "### Set up and run ATEK data preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "Ua3oo2TSsYm0",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Create ATEK preprocessor from conf. It will automatically choose which type of sample to build.\n",
    "atek_preprocessor = create_general_atek_preprocessor_from_conf(\n",
    "    # [required]\n",
    "    conf=preprocess_conf,\n",
    "    raw_data_folder = example_adt_data_dir,\n",
    "    sequence_name = sequence_name,\n",
    "    # [optional]\n",
    "    output_wds_folder=output_wds_path,\n",
    "    output_viz_file=os.path.join(example_adt_data_dir, \"atek_preprocess_viz.rrd\"),\n",
    "    category_mapping_file=category_mapping_file,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cxgiEJAFiDDH"
   },
   "source": [
    "## Preprocessed ATEK data sample content\n",
    "* Preprocessing input: VRS + csv + jsons\n",
    "* Preprocessing output (in memory): ATEK data samples: `Dict[torch.Tensor, str, or Dict]`\n",
    "* Preprocessing output (on local disk): WebDataset (WDS) tar files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "BS-OuwW9scUP",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "atek_data_sample = atek_preprocessor[0]\n",
    "atek_data_sample_dict = atek_data_sample.to_flatten_dict()\n",
    "print_data_sample_dict_content(atek_data_sample_dict)\n",
    "\n",
    "# Loop over all samples, and write valid ones to local tar files.\n",
    "atek_preprocessor.process_all_samples(write_to_wds_flag=True, viz_flag=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qDUCTF0gs48Y"
   },
   "source": [
    "## Visualize preprocessed ATEK data sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cVCo0il9abVi"
   },
   "outputs": [],
   "source": [
    "tar_file_urls = [os.path.join(output_wds_path, f\"shards-000{i}.tar\") for i in range(2)]\n",
    "atek_dataloader = create_native_atek_dataloader(urls = tar_file_urls, batch_size = None, num_workers = 1)\n",
    "atek_viz = NativeAtekSampleVisualizer(viz_prefix = \"notebook atek viz\", show_on_notebook = True, conf = viz_conf)\n",
    "for atek_sample in tqdm(islice(atek_dataloader, 10)):\n",
    "    atek_viz.plot_atek_sample_as_dict(atek_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LVbIgzI6jciw"
   },
   "source": [
    "# Part 2: Run Object detection inference using pre-trained CubeRCNN model\n",
    "In this example, we demonstrate how to run model inference with preprocessed ATEK data streamed from Data Store."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J2tOwBZ8k4cp"
   },
   "source": [
    "### Create PyTorch DataLoader, converted to CubeRCNN format\n",
    "User can add a data transform function from ATEK format -> CubeRCNN format:\n",
    "1. Dict key remapping.\n",
    "2. Tensor reshaping & reordering.\n",
    "3. Other data transformations.\n",
    "\n",
    "Example data transform function for CubeRCNN model: [src code](https://www.internalfb.com/code/fbsource/[a5c3831c045bc718862d1c512e84d4ed6f79d722]/fbcode/surreal/data_services/atek/atek/data_loaders/cubercnn_model_adaptor.py?lines=44-74)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "i7GgyyaWZvFB",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "logger = logging.getLogger()\n",
    "logger.info(\n",
    "    \"-------------------- ATEK WDS data can loaded into Model-specific format --------------- \"\n",
    ")\n",
    "# The CubeRCNN ModelAdaptor class is wrapped in this function\n",
    "cubercnn_dataloader = create_atek_dataloader_as_cubercnn(urls = tar_file_urls, batch_size = 1, num_workers = 1)\n",
    "first_cubercnn_sample = next(iter(cubercnn_dataloader))\n",
    "logger.info(f\"Loading WDS into CubeRCNN format, each sample contains the following keys: {first_cubercnn_sample[0].keys()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pWyaUUQPk6Te"
   },
   "source": [
    "### Run model inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-0RWOhlrjaKE"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "model_ckpt_path = \"/content/data/model_weights/ATEK_example_cubercnn_weights_trained_on_ADT\"\n",
    "# load pre-trained CubeRCNN model\n",
    "model_config_file = os.path.join(model_ckpt_path, \"config.yaml\")\n",
    "conf = OmegaConf.load(model_config_file)\n",
    "\n",
    "# setup config and model\n",
    "model_config, model = create_inference_model(\n",
    "    model_config_file, model_ckpt_path, use_cpu_only = True\n",
    ")\n",
    "\n",
    "# Cache inference results for visualization\n",
    "input_output_data_pairs = []\n",
    "\n",
    "# Loop over created Pytorch Dataloader, only 5 batches for demonstration\n",
    "with torch.no_grad():\n",
    "    for cubercnn_input_data in tqdm(\n",
    "       islice(cubercnn_dataloader, 5),\n",
    "        desc=\"Inference progress: \",\n",
    "    ):\n",
    "        cubercnn_model_output = model(cubercnn_input_data)\n",
    "\n",
    "        # cache inference results for visualization\n",
    "        input_output_data_pairs.append((cubercnn_input_data, cubercnn_model_output))\n",
    "\n",
    "logger.info(\"Inference completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uKegL5oFtEK-"
   },
   "source": [
    "## Visualize inference result\n",
    "\n",
    "If you did not see the visualization, please run the following code block again. Sometimes rerun visualization on colab notebook is not stable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "SHTdX-AxkZR_",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from atek.viz.cubercnn_visualizer import CubercnnVisualizer\n",
    "\n",
    "# Visualize cached inference results\n",
    "logger.info(\"Visualizing inference results.\")\n",
    "cubercnn_visualizer = CubercnnVisualizer(viz_prefix = \"inference_visualizer\", show_on_notebook = True, conf = viz_conf)\n",
    "# cubercnn_visualizer = CubercnnVisualizer(viz_prefix = \"inference_visualizer\", conf = infer_viz_conf)\n",
    "for input_data_as_list, output_data_as_list in input_output_data_pairs:\n",
    "    for single_cubercnn_input, single_cubercnn_output in zip(input_data_as_list, output_data_as_list):\n",
    "        timestamp_ns = single_cubercnn_input[\"timestamp_ns\"]\n",
    "        # Plot RGB image\n",
    "        cubercnn_visualizer.plot_cubercnn_img(single_cubercnn_input[\"image\"], timestamp_ns = timestamp_ns)\n",
    "\n",
    "        # Plot GT and prediction in different colors\n",
    "        single_cubercnn_output[\"T_world_camera\"] = single_cubercnn_input[\"T_world_camera\"] # This patch is needed for visualization\n",
    "        cubercnn_visualizer.plot_cubercnn_dict(cubercnn_dict = single_cubercnn_input, timestamp_ns = timestamp_ns, plot_color = cubercnn_visualizer.COLOR_GREEN, suffix = \"_model_input\")\n",
    "        cubercnn_visualizer.plot_cubercnn_dict(cubercnn_dict = single_cubercnn_output, timestamp_ns = timestamp_ns, plot_color = cubercnn_visualizer.COLOR_RED, suffix = \"_model_output\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ttd-XYROmW1E"
   },
   "source": [
    "## Part 3: Evaluate model performance\n",
    "ATEK provides **per-task**:\n",
    "1. Standardized prediction file formats.\n",
    "2. Lib for common eval metrics.\n",
    "3. Benchmarking scripts.\n",
    "\n",
    "Example prediction file format for 3D object detection:\n",
    "\n",
    "| time_ns       | tx_world_object | ty_world_object | tz_world_object | qw_world_object | qx_world_object | qy_world_object | qz_world_object | scale_x | scale_y | scale_z | name    | instance | sem_id | prob    |\n",
    "|---------------|-----------------|-----------------|-----------------|-----------------|-----------------|-----------------|-----------------|---------|---------|---------|---------|----------|--------|--------|\n",
    "| 14588033546600| -4.119894       | 0.986124        | 2.796770        | 0.008052        | -0.022706       | -0.010150       | 0.999658        | 0.190   | 2.146   | 0.900   | door    | -1       | 32     | 0.994462|\n",
    "| 14588033546600| -3.875954       | 0.837941        | 4.056602        | 0.009215        | -0.015670       | 0.999661        | -0.018645       | 0.325   | 1.697   | 0.964   | display | -1       | 37     | 0.994381|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ISxm_8RqmdIt"
   },
   "source": [
    "### Write inference results into ATEK-format csv files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AU9azyidmVUG"
   },
   "outputs": [],
   "source": [
    "from atek.evaluation.static_object_detection.obb3_csv_io import AtekObb3CsvWriter\n",
    "data_dir = \"/content/data\"\n",
    "os.makedirs(data_dir, exist_ok = True)\n",
    "\n",
    "gt_writer = AtekObb3CsvWriter(output_filename = os.path.join(data_dir, \"gt_obbs.csv\"))\n",
    "prediction_writer = AtekObb3CsvWriter(output_filename = os.path.join(data_dir, \"prediction_obbs.csv\"))\n",
    "\n",
    "for input_data_as_list, output_data_as_list in input_output_data_pairs:\n",
    "    for single_cubercnn_input, single_cubercnn_output in zip(input_data_as_list, output_data_as_list):\n",
    "        timestamp_ns = single_cubercnn_input[\"timestamp_ns\"]\n",
    "        single_cubercnn_output[\"T_world_camera\"] = single_cubercnn_input[\"T_world_camera\"]\n",
    "\n",
    "        gt_writer.write_from_cubercnn_dict(cubercnn_dict = single_cubercnn_input, timestamp_ns = timestamp_ns)\n",
    "        prediction_writer.write_from_cubercnn_dict(cubercnn_dict = single_cubercnn_output, timestamp_ns = timestamp_ns)\n",
    "logger.info(\"Finished writing obb csv files\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oUmOT3t8mq2n"
   },
   "source": [
    "### Call ATEK's benchmarking script to evaluate the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6snS7A2NmVEW"
   },
   "outputs": [],
   "source": [
    "benchmarking_command = [\n",
    "    \"python3\", f\"{atek_src_path}/tools/benchmarking_static_object_detection.py\",\n",
    "    \"--pred-csv\", f\"{data_dir}/prediction_obbs.csv\",\n",
    "    \"--gt-csv\", f\"{data_dir}/gt_obbs.csv\",\n",
    "    \"--output-file\", f\"{data_dir}/atek_metrics.json\"\n",
    "]\n",
    "return_code = run_command_and_display_output(benchmarking_command)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
